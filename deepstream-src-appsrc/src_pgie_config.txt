################################################################################
# Copyright (c) 2020-2021, NVIDIA CORPORATION. All rights reserved.
#
# Permission is hereby granted, free of charge, to any person obtaining a
# copy of this software and associated documentation files (the "Software"),
# to deal in the Software without restriction, including without limitation
# the rights to use, copy, modify, merge, publish, distribute, sublicense,
# and/or sell copies of the Software, and to permit persons to whom the
# Software is furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
# DEALINGS IN THE SOFTWARE.
################################################################################

# Following properties are mandatory when engine files are not specified:
#   int8-calib-file(Only in INT8)
#   Caffemodel mandatory properties: model-file, proto-file, output-blob-names
#   UFF: uff-file, input-dims, uff-input-blob-name, output-blob-names
#   ONNX: onnx-file
#
# Mandatory properties for detectors:
#   num-detected-classes
#
# Optional properties for detectors:
#   cluster-mode(Default=Group Rectangles), interval(Primary mode only, Default=0)
#   custom-lib-path,
#   parse-bbox-func-name
#
# Mandatory properties for classifiers:
#   classifier-threshold, is-classifier
#
# Optional properties for classifiers:
#   classifier-async-mode(Secondary mode only, Default=false)
#
# Optional properties in secondary mode:
#   operate-on-gie-id(Default=0), operate-on-class-ids(Defaults to all classes),
#   input-object-min-width, input-object-min-height, input-object-max-width,
#   input-object-max-height
#
# Following properties are always recommended:
#   batch-size(Default=1)
#
# Other optional properties:
#   net-scale-factor(Default=1), network-mode(Default=0 i.e FP32),
#   model-color-format(Default=0 i.e. RGB) model-engine-file, labelfile-path,
#   mean-file, gie-unique-id(Default=0), offsets, process-mode (Default=1 i.e. primary),
#   custom-lib-path, network-mode(Default=0 i.e FP32)
#
# The values in the config file are overridden by values set through GObject
# properties.

[property]
## 1. image preprocess

# variance
net-scale-factor=0.0039215697906911373

# Integer 0: RGB 1: BGR 2: GRAY
model-color-format=0

# Aspect ratio
#maintain-aspect-ratio=1

# Resize interploation
#scaling-filter=0

# Compute hardware to use for scaling frames / object crops to network resolution.
#scaling-compute-hw=0

# Indicates whether to pad image symmetrically while scaling input.
#symmetric-padding=0


## 2. build network

# When a network supports both implicit batch dimension and full dimension, force the implicit batch dimension mode.
force-implicit-batch-dim=1

# Number of frames or objects to be inferred together in a batch.
batch-size=1

# model file
tlt-model-key=tlt_encode
tlt-encoded-model=./models/tao_pretrained_models/trafficcamnet/resnet18_trafficcamnet_pruned.etlt

# build engine
int8-calib-file=./models/tao_pretrained_models/trafficcamnet/trafficnet_int8.txt
model-engine-file=./models/tao_pretrained_models/trafficcamnet/resnet18_trafficcamnet_pruned.etlt_b1_gpu0_fp16.engine

# label file
labelfile-path=./models/tao_pretrained_models/trafficcamnet/labels_trafficnet.txt

# Number of classes detected by the network (Detector)
num-detected-classes=4

# input frame size
infer-dims=3;544;960

# input layer
uff-input-blob-name=input_1

# output layer
output-blob-names=output_bbox/BiasAdd;output_cov/Sigmoid

# Name of the custom bounding box parsing function. If not specified.
#parse-bbox-func-name=parse_bbox_resnet

# Absolute pathname of a library containing custom method implementations for custom models.
#custom-lib-path=/home/­ubuntu/­libresnet_custom_impl.so

# 0=FP32, 1=INT8, 2=FP16 mode
network-mode=2

# Infer Processing Mode 1=Primary Mode 2=Secondary Mode
process-mode=1

# 0=detector, 1=classifier, 2=segmentatio, 3=instance segmentation, 100=other
network-type=0

# Enable tensor metadata output
output-tensor-meta=0


## 3. post-preprocess function

# Integer 0: OpenCV groupRectangles() 1: DBSCAN 2: Non Maximum Suppression 3: DBSCAN + NMS Hybrid 4: No clustering
cluster-mode=2


## 4.  Gst Properties

# Device ID of GPU to use for pre-processing/inference (dGPU only)
gpu-id=0

# Unique ID identifying metadata generated by this GIE
gie-unique-id=1

# Unique ID of the GIE on whose metadata (bounding boxes) this GIE is to operate on
#operate-on-gie-id=1

# Class IDs of the parent GIE on which this GIE is to operate on
#operate-on-class-ids=0

# Number of consecutive batches to be skipped for inference
interval=0

# There is a “workspace” parameter that limit the maximal memory amount for TensorRT. Default is set to 450Mb (450x1024x1024).
#workspace-size = 471859200


## 5. secondary detector

# Secondary GIE infers only on objects with this minimum height and width
#input-object-min-width=600
#input-object-min-height=340


[class-attrs-all]
# Detection threshold to be applied prior to clustering operation(NMS)
pre-cluster-threshold=0.1

# Detection threshold to be applied post clustering operation
#post-cluster-threshold=0.5

# Epsilon values for OpenCV grouprectangles() function and DBSCAN algorithm
eps=0.2

# Threshold value for rectangle merging for OpenCV grouprectangles() function
group-threshold=1

# Minimum number of points required to form a dense region for DBSCAN algorithm
#minBoxes=1

# Maximum IOU score between two proposals after which the proposal with the lower confidence will be rejected.
#nms-iou-threshold=0.5

# Offset of the RoI from the top of the frame. Only objects within the RoI are output.
roi-top-offset=0

# Offset of the RoI from the bottom of the frame. Only objects within the RoI are output.
roi-bottom-offset=0

# Minimum width in pixels of detected objects to be output by the GIE
detected-min-w=0

# Minimum height in pixels of detected objects to be output by the GIE
detected-min-h=0

# Maximum width in pixels of detected objects to be output by the GIE
detected-max-w=0

# Maximum height in pixels of detected objects to be output by the GIE
detected-max-h=0

